{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the paper\n",
    "\n",
    "We attempt to reproduce and beat the results of \"Distribution Regression with Sliced Wasserstein Kernels\", https://arxiv.org/pdf/2202.03926.pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPukgpJoRVA8"
   },
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from jax.config import config\n",
    "\n",
    "run64 = False\n",
    "if run64:\n",
    "    config.update(\"jax_enable_x64\", True)\n",
    "    global_type = jnp.float64\n",
    "else:\n",
    "    global_type = jnp.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UdOhJnZDRY2B"
   },
   "outputs": [],
   "source": [
    "import ott\n",
    "from ott.geometry import pointcloud\n",
    "from ott.core import sinkhorn\n",
    "from ott.tools import transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indexes_support(n, m):\n",
    "    rows = jnp.expand_dims(jnp.arange(n, dtype=jnp.float32), axis=1)\n",
    "    rows = jnp.tile(rows, m) / (n-1)  # renormalize\n",
    "    cols = jnp.expand_dims(jnp.arange(m, dtype=jnp.float32), axis=1)\n",
    "    cols = jnp.tile(cols, n).T / (m-1)  # renormalize\n",
    "    coords = jnp.stack([rows, cols], axis=-1)\n",
    "    coords = jnp.reshape(coords, newshape=(n*m, 2))\n",
    "    coords = coords*2. - 1.  # to [-1., 1.]\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Hide any GPUs from TensorFlow. Otherwise TF might reserve memory and make\n",
    "# it unavailable to JAX.\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(images):\n",
    "    return images.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def vizualize_features(features, channels='first', *, plot_size=3, filename=None, **kwargs):\n",
    "    if channels == 'last':\n",
    "        features = jnp.transpose(features, axes=[2, 3, 0, 1])\n",
    "    n, m = features.shape[2], features.shape[3]\n",
    "    n_row, n_col = features.shape[0], features.shape[1]\n",
    "    imgs = [features[i,j] for i, j in itertools.product(range(n_row), range(n_col))]\n",
    "    _, axs = plt.subplots(n_row, n_col, figsize=(n_col*plot_size, n_row*plot_size))\n",
    "    if n_row == 1 and n_col == 1:\n",
    "        axs = [axs]\n",
    "    else:\n",
    "        axs = axs.flatten()\n",
    "    for img, ax in zip(imgs, axs):\n",
    "        ax.imshow(img, **kwargs)\n",
    "    plt.show()\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename)\n",
    "        if plot_wandb:\n",
    "            wandb.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'SinkhornKernel-mnist.ipynb'\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "import math\n",
    "\n",
    "debug = False\n",
    "plot_wandb = not debug\n",
    "config = SimpleNamespace(\n",
    "    dataset_name='mnist',\n",
    "    train_size=1300,\n",
    "    test_size=1000,\n",
    "    epsilon=2e-3,\n",
    "    mu_type='uniform',\n",
    "    image_size=28,\n",
    "    jolib_mem=False,\n",
    "    rotation_range=0,\n",
    "    translation_range=6,\n",
    "    geometry='grid',\n",
    "    lbda=0.1\n",
    ")\n",
    "if plot_wandb:\n",
    "    wandb.init(project=\"sinkhorn_kernel_mnist\", config=config.__dict__, save_code=True)\n",
    "    table = wandb.Table(columns=['Algo', 'Type', 'Kfold acc', 'Test acc', 'Best params'])\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "if config.dataset_name == 'mnist':\n",
    "    loader = mnist\n",
    "elif config.dataset_name == 'fashion_mnist':\n",
    "    loader = fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = loader.load_data()\n",
    "x_train = normalize_images(x_train)\n",
    "x_test = normalize_images(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices = get_indexes_support(config.image_size, config.image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sinkhorn Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nonzero_pixels(img, support):\n",
    "    flat_img = img.flatten()\n",
    "    indices = flat_img.nonzero()\n",
    "    cloud_weight = flat_img[indices]\n",
    "    cloud_weight = cloud_weight / cloud_weight.sum()\n",
    "    cloud_support = support[indices]\n",
    "    return cloud_weight, cloud_support\n",
    "\n",
    "def image_average(images, support):\n",
    "    avg_img = images.mean(axis=0)\n",
    "    flat_mean = avg_img.flatten()\n",
    "    num_non_zero = int(jax.vmap(jnp.count_nonzero)(images).mean())\n",
    "    print(f\"Keep {num_non_zero} pixels\")\n",
    "    higher_indices = jnp.argsort(flat_mean)[::-1]\n",
    "    threshold = flat_mean[higher_indices[num_non_zero]]\n",
    "    mu_support = support[higher_indices[:num_non_zero]]\n",
    "    mu_weights = flat_mean[higher_indices[:num_non_zero]]\n",
    "    mu_weights = mu_weights / mu_weights.sum()\n",
    "    sparse_img = jnp.where(avg_img < threshold, 0., avg_img)\n",
    "    digits = jnp.stack([avg_img, sparse_img])[jnp.newaxis,:,:,:]\n",
    "    vizualize_features(digits)\n",
    "    return mu_weights, mu_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_uniform(images, support):\n",
    "    uniform = jnp.ones(images.shape[1:])\n",
    "    uniform = uniform.flatten()\n",
    "    uniform = uniform / uniform.sum()\n",
    "    return uniform, support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.mu_type == 'euclidian':\n",
    "    mu_weights, mu_support = image_average(x_train, all_indices)\n",
    "elif config.mu_type == 'uniform':\n",
    "    mu_weights, mu_support = mu_uniform(x_train, all_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_img_from_g(g_embedding, mu_support):\n",
    "    img_g = onp.full((config.image_size,config.image_size), fill_value=-jnp.inf)\n",
    "    for idx, value in zip(mu_support, g_embedding):\n",
    "        i, j = idx[0], idx[1]\n",
    "        i = round((i+1)*(config.image_size-1)/2)\n",
    "        j = round((j+1)*(config.image_size-1)/2)\n",
    "        img_g[i,j] = value\n",
    "    return img_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_distribution(image):\n",
    "    weights = image.sum(keepdims=True)\n",
    "    image = image / weights\n",
    "    return jnp.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ott\n",
    "from ott.geometry.pointcloud import PointCloud\n",
    "from ott.core import sinkhorn\n",
    "from ott.tools import transport\n",
    "\n",
    "def get_cloud_embedding(img, mu_weight, mu_support, epsilon, **kwargs):\n",
    "    img = normalize_distribution(img)\n",
    "    img_weight, img_support = filter_nonzero_pixels(img, all_indices)\n",
    "    geom = PointCloud(img_support, mu_support, epsilon=epsilon)\n",
    "    ot_sol = sinkhorn.sinkhorn(geom, img_weight, mu_weight, **kwargs)\n",
    "    return ot_sol.g, ot_sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ott.geometry import grid\n",
    "\n",
    "def fill_void(img, lbda):\n",
    "    eps  = 0.1 / (img.shape[-2]*img.shape[-1])\n",
    "    mask = jnp.where(img > 0, 0., 1.)\n",
    "    mask = mask / (jnp.sum(mask, axis=[-2,-1], keepdims=True) + eps)\n",
    "    img = img + lbda * mask\n",
    "    img = img / jnp.sum(img, axis=[-2,-1], keepdims=True)\n",
    "    return img\n",
    "\n",
    "def get_grid_embedding(img, mu_weight, mu_support, epsilon, **kwargs):\n",
    "    img_weight = fill_void(img, lbda=config.lbda).flatten()\n",
    "    geom = grid.Grid(grid_size=[img.shape[-2], img.shape[-1]], epsilon=epsilon)\n",
    "    ot_sol = sinkhorn.sinkhorn(geom, img_weight.flatten(), mu_weight.flatten(), **kwargs)\n",
    "    return ot_sol.g, ot_sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.geometry == 'cloud':\n",
    "    get_img_embedding = get_cloud_embedding\n",
    "elif config.geometry == 'grid':\n",
    "    get_img_embedding = get_grid_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import rotate, AffineTransform, warp, resize\n",
    "import tqdm\n",
    "\n",
    "def shift(image, translation):\n",
    "    transform = AffineTransform(translation=translation)\n",
    "    shifted = warp(image, transform, preserve_range=True)\n",
    "    shifted = shifted.astype(image.dtype)\n",
    "    return shifted\n",
    "\n",
    "def evaluate_embeddings(x_sample, epsilon, filename=None, transform=None):\n",
    "    if transform is None:\n",
    "        shifted_small = shift(onp.array(x_sample), translation=(3, 0))\n",
    "        shifted_large = shift(onp.array(x_sample), translation=(0, 6))\n",
    "        rotated_15 = rotate(onp.array(x_sample), angle=15)\n",
    "        rotated_30 = rotate(onp.array(x_sample), angle=-30)\n",
    "        transformed_sample = [x_sample, shifted_small, shifted_large, rotated_15, rotated_30]\n",
    "    else:\n",
    "        transformed_sample = [transform(x_sample) for _ in range(4)]\n",
    "    imgs = []\n",
    "    x_sample_g, _ = get_img_embedding(x_sample, mu_weights, mu_support, epsilon)\n",
    "    for img in tqdm.tqdm(transformed_sample):\n",
    "        g_embeddings, ot_sol = get_img_embedding(img, mu_weights, mu_support, epsilon=epsilon)\n",
    "        img_g = get_img_from_g(g_embeddings, mu_support)\n",
    "        delta_g = get_img_from_g(g_embeddings - x_sample_g, mu_support)\n",
    "        if x_sample.shape != img.shape:\n",
    "            img = resize(img, x_sample.shape)\n",
    "        delta_euclidian = img - x_sample\n",
    "        imgs.append(jnp.stack([img, img_g, delta_g, delta_euclidian]))\n",
    "    imgs = jnp.stack(imgs)\n",
    "    imgs = jnp.transpose(imgs, axes=[1,0,2,3])\n",
    "    vizualize_features(imgs, plot_size=2, cmap='plasma', filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import EuclideanTransform\n",
    "from skimage.util import crop\n",
    "\n",
    "def transform_fn(rotation_range, translation_range, crop_back=None, extend_size=3):\n",
    "    crop_back = config.geometry == 'grid'\n",
    "    def transform(image):\n",
    "        image = onp.pad(image, (extend_size, extend_size), 'constant', constant_values=(0, 0))\n",
    "        rotation = onp.random.uniform(-rotation_range, rotation_range) / 180 * onp.pi\n",
    "        translation = onp.random.uniform(-translation_range, translation_range, size=2)\n",
    "        euclidian = EuclideanTransform(rotation=rotation, translation=translation)\n",
    "        image = warp(image, euclidian)\n",
    "        a = onp.random.randint(0, 2*extend_size+1)\n",
    "        b = onp.random.randint(0, 2*extend_size+1)\n",
    "        crop_width = [(a, 2*extend_size-a), (b, 2*extend_size-b)]\n",
    "        if crop_back:\n",
    "            image = crop(image, crop_width=crop_width)\n",
    "        return image\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_transform = transform_fn(rotation_range=config.rotation_range, translation_range=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = onp.array([default_transform(x_sample) for x_sample in x_train[:16]]).reshape((4, 4,)+x_train.shape[1:])\n",
    "vizualize_features(transformed, plot_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample = jnp.array(x_train[onp.random.choice(len(x_train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_embeddings(x_sample, epsilon=1., filename=f'embedding_{1.}.png', transform=default_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_embeddings(x_sample, epsilon=1e-3, filename=f'embedding_{1e-3}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tqdm\n",
    "\n",
    "def encode_imgs(x_ds, y_ds, ds_size, transform=None, filename=None):\n",
    "    features = []\n",
    "    raw = []\n",
    "    labels = []\n",
    "    try:\n",
    "        pbar = tqdm.tqdm(total=ds_size)\n",
    "        converged_hist = []\n",
    "        for image, label in zip(*shuffle(x_ds, y_ds, n_samples=ds_size)):\n",
    "            if transform is not None:\n",
    "                image = transform(image)\n",
    "            g_embeddings, ot_sol = get_img_embedding(jnp.array(image), mu_weights, mu_support, epsilon=config.epsilon)\n",
    "            features.append(g_embeddings)\n",
    "            labels.append(label)\n",
    "            raw.append(image.ravel())\n",
    "            converged_hist.append(ot_sol.converged)\n",
    "            pbar.set_postfix({'converged':jnp.mean(jnp.array(converged_hist))})\n",
    "            pbar.update()\n",
    "        features = jnp.stack(features).reshape((len(features), -1))\n",
    "        raw = jnp.stack(raw, axis=0).reshape((len(raw), -1))\n",
    "        labels  = jnp.stack(labels)\n",
    "    finally:\n",
    "        pbar.close()\n",
    "    if filename is not None:\n",
    "        jnp.savez(filename, features=features, raw=raw, labels=labels)\n",
    "    return features, raw, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, raw, labels = encode_imgs(x_train, y_train, config.train_size, filename=f'train_{config.epsilon}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test, raw_test, labels_test = encode_imgs(x_test, y_test, config.test_size, filename=f'test_{config.epsilon}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(*onp.unique(labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(*onp.unique(labels_test, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_svc(x, labels):\n",
    "    learner = Pipeline([('scaler', StandardScaler(with_std=False)), ('svc', SVC())])\n",
    "    cv = GridSearchCV(learner, param_grid={'svc__gamma':10**onp.linspace(-4, 2, 12), 'svc__C':10**onp.linspace(-4, 4, 12)},\n",
    "                      cv=5, scoring='accuracy',  # balanced learning so ok.\n",
    "                      refit=True,  # refit best estimator found in grid search\n",
    "                      n_jobs=12, verbose=1)  # keep 4 cores for other process running in parallel\n",
    "    cv = cv.fit(onp.array(x).astype(jnp.float64), labels)\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv_features = grid_search_svc(onp.array(features).astype(jnp.float64), labels)\n",
    "grid_cv_features.best_score_, grid_cv_features.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = grid_cv_features.best_estimator_\n",
    "features_test_pred = best_features.predict(features_test)\n",
    "features_test_acc = (features_test_pred == labels_test).mean()\n",
    "print(f\"{features_test_acc*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_wandb:\n",
    "    table.add_data('svc', 'features', grid_cv_features.best_score_, features_test_acc, grid_cv_features.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_raw = SVC()\n",
    "grid_cv_raw = grid_search_svc(onp.array(raw).astype(jnp.float64), labels)\n",
    "grid_cv_raw.best_score_, grid_cv_raw.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_raw = grid_cv_raw.best_estimator_\n",
    "raw_test_pred = best_raw.predict(raw_test)\n",
    "raw_test_acc = (raw_test_pred == labels_test).mean()\n",
    "print(f\"{raw_test_acc*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_wandb:\n",
    "    table.add_data('svc', 'raw', grid_cv_features.best_score_, raw_test_acc, grid_cv_features.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation of MNIST\n",
    "Use https://scikit-image.org/docs/dev/api/skimage.transform.html#skimage.transform.EuclideanTransform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_transform, raw_transform, labels_transform = encode_imgs(x_test, y_test, config.test_size, transform=transform, filename=f'transform_{config.epsilon}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "raw_transform = onp.array([resize(img_raw, (28, 28)).flatten() for img_raw in raw_transform])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(*onp.unique(labels_transform, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = grid_cv_features.best_estimator_\n",
    "features_transform_pred = best_features.predict(features_transform)\n",
    "features_transform_acc = (features_transform_pred == labels_transform).mean()\n",
    "print(f\"{features_transform_acc*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(*onp.unique(features_transform_pred, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_wandb:\n",
    "    table.add_data('svc', 'features_transform', None, features_transform_acc, grid_cv_features.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_raw = grid_cv_raw.best_estimator_\n",
    "raw_transform_pred = best_raw.predict(raw_transform)\n",
    "raw_transform_acc = (raw_transform_pred == labels_transform).mean()\n",
    "print(f\"{raw_transform_acc*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(*onp.unique(raw_transform_pred, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_wandb:\n",
    "    table.add_data('svc', 'raw_transform', None, raw_transform_acc, grid_cv_raw.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SinkhornKernel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
