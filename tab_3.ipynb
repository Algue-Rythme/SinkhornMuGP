{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rU37BVmof05",
        "outputId": "638cf5b7-d8b2-4b59-cb39-48333977b8e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jaxopt\n",
            "  Downloading jaxopt-0.5-py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from jaxopt) (3.2.2)\n",
            "Requirement already satisfied: jaxlib>=0.1.69 in /usr/local/lib/python3.7/dist-packages (from jaxopt) (0.3.20+cuda11.cudnn805)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jaxopt) (1.7.3)\n",
            "Requirement already satisfied: jax>=0.2.18 in /usr/local/lib/python3.7/dist-packages (from jaxopt) (0.3.21)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from jaxopt) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.18.4 in /usr/local/lib/python3.7/dist-packages (from jaxopt) (1.21.6)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.18->jaxopt) (0.8.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.18->jaxopt) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.18->jaxopt) (4.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.1->jaxopt) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.1->jaxopt) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.1->jaxopt) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.1->jaxopt) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.0.1->jaxopt) (1.15.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.2.18->jaxopt) (5.9.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.2.18->jaxopt) (3.8.1)\n",
            "Installing collected packages: jaxopt\n",
            "Successfully installed jaxopt-0.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gpjax\n",
            "  Downloading GPJax-0.4.13.tar.gz (24 kB)\n",
            "Requirement already satisfied: jax>=0.1.67 in /usr/local/lib/python3.7/dist-packages (from gpjax) (0.3.21)\n",
            "Requirement already satisfied: jaxlib>=0.1.47 in /usr/local/lib/python3.7/dist-packages (from gpjax) (0.3.20+cuda11.cudnn805)\n",
            "Collecting optax\n",
            "  Downloading optax-0.1.3-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 7.1 MB/s \n",
            "\u001b[?25hCollecting chex\n",
            "  Downloading chex-0.1.5-py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting distrax>=0.1.2\n",
            "  Downloading distrax-0.1.2-py3-none-any.whl (272 kB)\n",
            "\u001b[K     |████████████████████████████████| 272 kB 45.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-probability>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from gpjax) (0.16.0)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from gpjax) (4.64.1)\n",
            "Collecting ml-collections==0.1.0\n",
            "  Downloading ml_collections-0.1.0-py3-none-any.whl (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 7.4 MB/s \n",
            "\u001b[?25hCollecting jaxtyping>=0.0.2\n",
            "  Downloading jaxtyping-0.2.7-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from ml-collections==0.1.0->gpjax) (0.5.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from ml-collections==0.1.0->gpjax) (6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from ml-collections==0.1.0->gpjax) (1.15.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from ml-collections==0.1.0->gpjax) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from distrax>=0.1.2->gpjax) (1.21.6)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex->gpjax) (0.12.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex->gpjax) (0.1.7)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.67->gpjax) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.67->gpjax) (4.1.1)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.67->gpjax) (1.7.3)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.67->gpjax) (0.8.0)\n",
            "Collecting typeguard>=2.13.3\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Collecting typing-extensions\n",
            "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.16.0->gpjax) (0.5.3)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.16.0->gpjax) (1.5.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.16.0->gpjax) (4.4.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.67->gpjax) (3.8.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.67->gpjax) (5.9.0)\n",
            "Building wheels for collected packages: gpjax\n",
            "  Building wheel for gpjax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpjax: filename=GPJax-0.4.13-py3-none-any.whl size=28998 sha256=4417623003f4b88f1e7fb9b3f1a03158be82c98a8295854dae0df65784b0f3f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/af/87/4b559d0f0d68a695d7b2a113714d7deb5f8871c39642b3355f\n",
            "Successfully built gpjax\n",
            "Installing collected packages: typing-extensions, typeguard, chex, optax, ml-collections, jaxtyping, distrax, gpjax\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 2.7.1\n",
            "    Uninstalling typeguard-2.7.1:\n",
            "      Successfully uninstalled typeguard-2.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.1.2 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\n",
            "spacy 3.4.1 requires typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\n",
            "confection 0.0.2 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed chex-0.1.5 distrax-0.1.2 gpjax-0.4.13 jaxtyping-0.2.7 ml-collections-0.1.0 optax-0.1.3 typeguard-2.13.3 typing-extensions-4.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ott-jax\n",
            "  Downloading ott_jax-0.2.9-py3-none-any.whl (179 kB)\n",
            "\u001b[K     |████████████████████████████████| 179 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from ott-jax) (3.2.2)\n",
            "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.7/dist-packages (from ott-jax) (6.0)\n",
            "Requirement already satisfied: jax>=0.1.67 in /usr/local/lib/python3.7/dist-packages (from ott-jax) (0.3.21)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from ott-jax) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.7/dist-packages (from ott-jax) (1.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from ott-jax) (5.0.0)\n",
            "Requirement already satisfied: numpy!=1.23.0,>=1.18.4 in /usr/local/lib/python3.7/dist-packages (from ott-jax) (1.21.6)\n",
            "Collecting flax>=0.3.6\n",
            "  Downloading flax-0.6.1-py3-none-any.whl (185 kB)\n",
            "\u001b[K     |████████████████████████████████| 185 kB 41.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from ott-jax) (4.4.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from ott-jax) (1.2.0)\n",
            "Requirement already satisfied: jaxlib>=0.1.47 in /usr/local/lib/python3.7/dist-packages (from ott-jax) (0.3.20+cuda11.cudnn805)\n",
            "Requirement already satisfied: optax>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from ott-jax) (0.1.3)\n",
            "Collecting rich>=11.1\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 44.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from flax>=0.3.6->ott-jax) (1.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->ott-jax) (3.8.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.67->ott-jax) (3.3.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.67->ott-jax) (0.8.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.1->ott-jax) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.1->ott-jax) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.1->ott-jax) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.1->ott-jax) (3.0.9)\n",
            "Requirement already satisfied: chex>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from optax>=0.1.1->ott-jax) (0.1.5)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax>=0.1.1->ott-jax) (0.12.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax>=0.1.1->ott-jax) (0.1.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.0.1->ott-jax) (1.15.0)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich>=11.1->flax>=0.3.6->ott-jax) (2.6.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0->ott-jax) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0->ott-jax) (3.1.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.67->ott-jax) (5.9.0)\n",
            "Installing collected packages: commonmark, rich, flax, ott-jax\n",
            "Successfully installed commonmark-0.9.1 flax-0.6.1 ott-jax-0.2.9 rich-12.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install jaxopt\n",
        "!pip install gpjax\n",
        "!pip install ott-jax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO7R6V6hSrkM"
      },
      "source": [
        "## GP Jax preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEK4uZVXSpJx"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "from jax.scipy.sparse.linalg import gmres\n",
        "from jax.lax import custom_linear_solve\n",
        "from jax.numpy.linalg import slogdet\n",
        "import jax.numpy as jnp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNwaueawSyaT"
      },
      "outputs": [],
      "source": [
        "from jax.config import config\n",
        "# config.update(\"jax_enable_x64\", True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VykE82iwSzZ0"
      },
      "outputs": [],
      "source": [
        "import jax.random as jr\n",
        "import gpjax as gpx\n",
        "from functools import partial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVdnHFcbm6Yz"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "# sns.set_context(\"notebook\")\n",
        "sns.set_context(\"paper\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsFVkR2e15OF"
      },
      "source": [
        "## GP Sinkhorn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mh56aiJBVw3b"
      },
      "outputs": [],
      "source": [
        "import jax.numpy as jnp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PjLnXsRB89UB"
      },
      "outputs": [],
      "source": [
        "# Found by running NoteBook LearnSinkhornParameters.ipynb\n",
        "\n",
        "mu_cloud_57 = jnp.array([[ 0.21957754,  0.35253927],\n",
        "              [ 0.09953722,  0.43077431],\n",
        "              [ 0.9886206 ,  0.11487304],\n",
        "              [-0.83145712,  0.1669271 ],\n",
        "              [ 0.27657292,  0.12463248],\n",
        "              [-0.06175206,  0.21355569],\n",
        "              [-0.04373814,  0.23610753],\n",
        "              [ 0.30061063,  0.15764027],\n",
        "              [ 0.10935807,  0.41247011],\n",
        "              [-0.01664592,  0.29173418],\n",
        "              [ 0.87559493, -0.05147166],\n",
        "              [-0.08324035,  0.21878795]], dtype=jnp.float32)\n",
        "mu_weight_57 = jnp.array([ 9.62563782e-03,  8.53329137e-03, -1.21150131e-01,\n",
        "               4.27755472e-01, -3.74874932e-04, -2.53500209e-02,\n",
        "               1.69277536e-03, -3.16603754e-02, -1.62934858e-02,\n",
        "              -2.89706357e-02, -1.59076041e-01, -6.47316129e-02])\n",
        "\n",
        "mu_cloud_56 = jnp.array([[-0.18145709,  0.20396382],\n",
        "              [-0.17958481,  0.20788199],\n",
        "              [-1.44540799, -1.63469062],\n",
        "              [ 2.0360876 , -0.12869805],\n",
        "              [ 1.57829722, -0.18106633],\n",
        "              [-0.26955691,  0.09504965],\n",
        "              [ 0.34187511, -0.54820849],\n",
        "              [ 0.30926302, -0.48505812],\n",
        "              [ 0.04961068,  1.89436538],\n",
        "              [ 0.05049443,  1.9277267 ],\n",
        "              [-1.39822343, -1.20600227],\n",
        "              [ 0.04183291,  1.54766735]])\n",
        "mu_weight_56 = jnp.array([ 1.11278815,  1.0128134 , -0.35208267, -0.2118818 ,\n",
        "              -0.13187659, -0.0698886 ,  0.27349365,  0.07536408,\n",
        "              -0.57247179, -0.55270456, -0.04717465, -0.53637863])\n",
        "\n",
        "mu_cloud_46 = jnp.array([[ 1.3449012 ,  2.13853616],\n",
        "              [ 0.45771468, -0.16584545],\n",
        "              [-1.39573938, -1.01686017],\n",
        "              [-0.19325787,  1.67778046],\n",
        "              [-0.48856439, -2.10435212],\n",
        "              [ 0.5307469 , -0.81295445]], dtype=jnp.float32)\n",
        "mu_weight_46 = jnp.array([-0.16987539,  0.04750267,  0.46313042, -0.18759383,\n",
        "               0.05566591, -0.20882978], dtype=jnp.float32)\n",
        "\n",
        "mu_cloud_46_5 = jnp.array([[ 0.22206083,  1.71624839],\n",
        "              [-0.43609571, -0.50998092],\n",
        "              [-0.19480746,  0.93104592],\n",
        "              [-0.38481522, -2.075897  ],\n",
        "              [-0.12979581, -0.1755457 ]], dtype=jnp.float32)\n",
        "mu_weight_46_5 = jnp.array([-0.13618056,  0.35912072, -0.59738579,  0.60334502,\n",
        "              -0.2288994 ], dtype=jnp.float32)\n",
        "\n",
        "mu_cloud_46_4 = jnp.array([[-0.19373875, -1.8789795 ],\n",
        "              [-0.14753972,  1.90018948],\n",
        "              [ 0.16684833, -0.23762417],\n",
        "              [ 0.11818121, -0.75299912]], dtype=jnp.float32)\n",
        "mu_weight_46_4 = jnp.array([ 0.99958116,  0.82718838,  1.90731148, -3.73408101], dtype=jnp.float32)\n",
        "\n",
        "mu = mu_cloud_46_4, mu_weight_46_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "j2RVVuBg8Je5"
      },
      "outputs": [],
      "source": [
        "def cloud_coordinates(image_size, pad_size):\n",
        "  img_size = image_size - 2*pad_size\n",
        "  steps = jnp.linspace(-1, 1., num=img_size, endpoint=True)\n",
        "  x, y = jnp.meshgrid(steps, steps)\n",
        "  x = x.flatten()\n",
        "  y = y.flatten()\n",
        "  grid = jnp.stack([x, y]).T\n",
        "  grid = jnp.array(grid, dtype=jnp.float32)\n",
        "  return grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Dk7ES6-N3WDe"
      },
      "outputs": [],
      "source": [
        "from typing import Any, Optional\n",
        "from dataclasses import dataclass\n",
        "from jaxopt.tree_util import tree_l2_norm\n",
        "from jaxopt import LBFGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEc0SA8K9lrZ"
      },
      "outputs": [],
      "source": [
        "def mean_cloud_embedding(cloud, mu_params, init_dual, **kwargs):\n",
        "  del init_dual  # unused\n",
        "  coordinates, weights = cloud\n",
        "  mu_cloud, _ = mu_params\n",
        "  mean_cloud = jnp.sum(coordinates * weights[:,:,jnp.newaxis], axis=1, keepdims=True)\n",
        "  pairwise_dist = jnp.sum((mean_cloud - mu_cloud[jnp.newaxis,:,:])**2, axis=-1)\n",
        "  return pairwise_dist, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WL7QVmOB4X67"
      },
      "outputs": [],
      "source": [
        "from ott.geometry import pointcloud\n",
        "import ott.core.sinkhorn as sinkhorn\n",
        "\n",
        "\n",
        "def mu_cloud_embedding(cloud, mu,\n",
        "                       image_size=28,\n",
        "                       pad_size=0,\n",
        "                       **kwargs):\n",
        "  weights = cloud  # unpack distribution\n",
        "  mu_cloud, mu_weight = mu  # unpack distribution\n",
        "\n",
        "  sinkhorn_epsilon = kwargs.pop('sinkhorn_epsilon')\n",
        "  cloud_coords = cloud_coordinates(image_size=image_size, pad_size=pad_size)\n",
        "\n",
        "  mu_w = jax.nn.softmax(mu_weight) if mu_weight is not None else None  # ensure it is a probability distribution\n",
        "  mu_c = mu_cloud - jnp.mean(mu_cloud, axis=0, keepdims=True)  # invariance by translation : recenter mu around its mean\n",
        "  scale = 1.0\n",
        "  mu_c = scale * jnp.tanh(mu_c)\n",
        "\n",
        "  # common geometry for all images\n",
        "  geom = pointcloud.PointCloud(cloud_coords, mu_c,\n",
        "                               epsilon=sinkhorn_epsilon)\n",
        "\n",
        "  def sinkhorn_single_cloud(cloud_weight):\n",
        "    out = sinkhorn.sinkhorn(geom, cloud_weight, mu_w,\n",
        "                            **kwargs)\n",
        "    return out\n",
        "\n",
        "  parallel_sinkhorn = jax.vmap(sinkhorn_single_cloud,\n",
        "                               in_axes=0,\n",
        "                               out_axes=0)\n",
        "  \n",
        "  outs = parallel_sinkhorn(weights)\n",
        "  init_dual = outs.f, outs.g  # for warm start\n",
        "  return outs.g, init_dual\n",
        "  \n",
        "kwargs = dict(\n",
        "    sinkhorn_epsilon               = 1e-1 ,\n",
        "    lse_mode                       = True ,\n",
        "    implicit_differentiation       = False,\n",
        "    implicit_solver_ridge_kernel   = 1e-2 ,  # promote zero sum solutions\n",
        "    implicit_solver_ridge_identity = 1e-2 ,  # regul for ill-posed problem\n",
        ")\n",
        "\n",
        "cloud_embedding_fn = partial(mu_cloud_embedding, **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPzgUvKz13Yf"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXCVwqOF84Vi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from jax.image import resize\n",
        "tf.config.experimental.set_visible_devices([], 'GPU')\n",
        "\n",
        "def img_to_cloud(image, image_size, pad_size):\n",
        "  image = resize(image, (image_size, image_size), \"cubic\")\n",
        "  sliced_cropped = slice(pad_size, image_size-pad_size, None)\n",
        "  image   = image[sliced_cropped, sliced_cropped]\n",
        "  weights = image.flatten()\n",
        "  weights = weights / jnp.sum(weights)\n",
        "  weights = jnp.array(weights, dtype=jnp.float32)\n",
        "  return weights\n",
        "\n",
        "\n",
        "# 4,6 for mnist toy\n",
        "# 5,7 for sandals, sneakers\n",
        "# 0,5 for tee-shirt, sandals\n",
        "def process_mnist(seed, ds_size, image_size=28, pad_size=2, digits=[4, 6]):  \n",
        "  train_mnist, (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "  # train_mnist, (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "  del train_mnist  # unused\n",
        "  # select two classes\n",
        "  target_0 = y_test == digits[0]\n",
        "  target_1 = y_test == digits[1]\n",
        "  sample_0 = x_test[target_0]\n",
        "  sample_1 = x_test[target_1]\n",
        "  # build subset\n",
        "  sample = jnp.concatenate([sample_0, sample_1])\n",
        "  target = jnp.concatenate([jnp.zeros(len(sample_0)), jnp.ones(len(sample_1))])\n",
        "  target = target.reshape((-1, 1))\n",
        "  # shuffle data\n",
        "  key = jax.random.PRNGKey(seed)\n",
        "  indices = jax.random.permutation(key, len(sample))\n",
        "  sample = sample[indices]\n",
        "  target = target[indices]\n",
        "  # keep few points\n",
        "  sample = sample[:ds_size]\n",
        "  target = target[:ds_size]\n",
        "  # make a cloud\n",
        "  img_to_cloud_fun = partial(img_to_cloud, image_size=image_size, pad_size=pad_size)\n",
        "  sample_cloud = jax.vmap(img_to_cloud_fun, in_axes=0, out_axes=0)(sample)\n",
        "  return sample_cloud, target, sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcQItt7c2nzz"
      },
      "source": [
        "## Training loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkwqdN8tOIAD"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from pprint import PrettyPrinter\n",
        "import numpy as onp\n",
        "\n",
        "pp = PrettyPrinter(indent=4)\n",
        "\n",
        "def plot_loss(losses, ax):\n",
        "  timesteps = onp.arange(len(losses))\n",
        "  sns.lineplot(x=timesteps, y=losses, ax=ax)\n",
        "  ax.set_xlabel('Timesteps')\n",
        "  ax.set_ylabel('Loss')\n",
        "  ax.set_title('Negative Log Marginal Likelihood')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5y04c-eJA9J"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score\n",
        "\n",
        "\n",
        "def evaluate(kernel_params,\n",
        "             posterior, likelihood, constrainer, unconstrainer,\n",
        "             sample_train, sample_test, y_train, y_test, prefix=''):\n",
        "  X_train = sample_train\n",
        "  X_test = sample_test\n",
        "  D = gpx.Dataset(X=X_train, y=y_train)\n",
        "  posterior_fn = posterior(D, kernel_params)\n",
        "\n",
        "  latent_dist = posterior_fn(X_test)\n",
        "  predictive_dist = likelihood(latent_dist, kernel_params)\n",
        "  predictive_mean = predictive_dist.mean()\n",
        "  predictive_std = predictive_dist.stddev()\n",
        "\n",
        "  try:\n",
        "    predictive_mean = predictive_mean.flatten()\n",
        "    evs = explained_variance_score(y_test.flatten(), predictive_mean)\n",
        "    label_pred = (predictive_mean >= 0.5).astype(y_test.dtype)\n",
        "    acc = jnp.mean(label_pred == y_test.flatten())\n",
        "  except Exception as e:\n",
        "    evs = float('nan')\n",
        "    acc = float('nan')\n",
        "  \n",
        "  log_likelihood = posterior.marginal_log_likelihood(D, constrainer)(gpx.transform(kernel_params, unconstrainer))\n",
        "  msg = f\"[GPJAX] TrainSetSize={len(X_train)} {prefix}Acc={acc*100:.3f}% evs={evs:.5f} log-likelihood={log_likelihood:.3f}\"\n",
        "  print(msg)\n",
        "  return evs, acc, log_likelihood"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EvUCuLDn7PZ"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def learn(opt, opt_update, loss_fn,\n",
        "          posterior, likelihood, constrainer, unconstrainer,\n",
        "          sample_train, sample_test,\n",
        "          y_train, y_test,\n",
        "          verbose=False):\n",
        "  ## init GP params\n",
        "  parameter_state = gpx.initialise(posterior, key=None)\n",
        "  constrained_kernel_params, _, _, _ = parameter_state.unpack()\n",
        "  kernel_params = gpx.transform(constrained_kernel_params, unconstrainer)\n",
        "\n",
        "  if verbose:\n",
        "    print('Unconstrained params:', end='');\n",
        "    pp.pprint(constrained_kernel_params)\n",
        "    print('Constrained params:', end='');\n",
        "    pp.pprint(kernel_params)\n",
        "  \n",
        "  ## Parameters to be optimized by LBFGS\n",
        "  params = {'kernel_params':kernel_params}\n",
        "\n",
        "  opt_state = opt.init_state(params)\n",
        "  losses = [float(loss_fn(params))]\n",
        "  log_rate = 1\n",
        "  pb = tqdm(range(opt.maxiter))\n",
        "  for step in range(opt.maxiter):\n",
        "    params, opt_state = opt_update(params, opt_state)\n",
        "    loss_val = opt_state.value\n",
        "    losses.append(float(loss_val))\n",
        "    if step % log_rate == 0:\n",
        "      pb.update(log_rate)\n",
        "      kernel_params = params['kernel_params']\n",
        "      kernel_params = gpx.transform(kernel_params, constrainer)\n",
        "      train_metrics = evaluate(kernel_params,\n",
        "           posterior, likelihood, constrainer, unconstrainer,\n",
        "           sample_train, sample_train, y_train, y_train, prefix='Train')\n",
        "      pb.set_postfix({\"Objective\": f\"{loss_val: .2f}\",\n",
        "                      \"TrainAcc\" : train_metrics[1]*100\n",
        "                      })\n",
        "  pb.close()\n",
        "  print('')\n",
        "\n",
        "  kernel_params = params['kernel_params']\n",
        "  kernel_params = gpx.transform(kernel_params, constrainer)\n",
        "  pp.pprint(kernel_params)\n",
        "\n",
        "  test_metrics = evaluate(kernel_params,\n",
        "           posterior, likelihood, constrainer, unconstrainer,\n",
        "           sample_train, sample_test, y_train, y_test, prefix='Test')\n",
        "\n",
        "  return kernel_params, (losses, test_metrics, train_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tabcbham7bxB"
      },
      "outputs": [],
      "source": [
        "from typing import Dict\n",
        "from jaxtyping import Array, Float\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass(repr=False)\n",
        "class MMD_Mnist(gpx.kernels.Kernel):\n",
        "  image_size: int = 28\n",
        "  pad_size: int = 0\n",
        "  name: Optional[str] = \"Maximum Mean Discrepancy\"\n",
        "\n",
        "  def __post_init__(self, ):\n",
        "    self.ndims = 1 if not self.active_dims else len(self.active_dims)\n",
        "    lengthscale = 2.\n",
        "    self.coords = cloud_coordinates(image_size=self.image_size, pad_size=self.pad_size)\n",
        "\n",
        "    # TODO: pre-compute.\n",
        "    coords = self.coords / 1.0  # shape (size_cloud, 2)\n",
        "    left_coords = coords[:,jnp.newaxis,:]  # shape (size_cloud, 1, 2)\n",
        "    right_coords = coords[jnp.newaxis,:,:]  # shape (1, size_cloud, 2)\n",
        "    squared_distance = jnp.sum((left_coords - right_coords) ** 2, axis=-1)\n",
        "    K = jnp.exp(-0.5 * squared_distance)  # shape (size_cloud, size_cloud)\n",
        "    self.K = K\n",
        "\n",
        "  def __call__(self, x, y, params):\n",
        "    K = self.K\n",
        "\n",
        "    xx = x[:,jnp.newaxis] * x[jnp.newaxis,:]\n",
        "    yy = y[:,jnp.newaxis] * y[jnp.newaxis,:]\n",
        "    xy = x[:,jnp.newaxis] * y[jnp.newaxis,:]\n",
        "    weights = xx + yy - 2*xy  # shape (size_cloud)\n",
        "    weights = weights * (len(x)*len(y))**0.5\n",
        "    mmd_dst = jnp.sum(weights * K)  # shape (,)\n",
        "\n",
        "    similarity = jnp.exp(-params[\"smoothness \"] * mmd_dst**2)\n",
        "    similarity = params[\"variance\"] * similarity\n",
        "\n",
        "    return jnp.squeeze(similarity)\n",
        "\n",
        "  def _initialise_params(self, key: jnp.DeviceArray) -> Dict:\n",
        "    return {\n",
        "        \"lengthscale\": jnp.array([1.0]),\n",
        "        \"smoothness \": jnp.array([1.0]),\n",
        "        \"variance\": jnp.array([1.0]),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5zO6-OPdoIR"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def run_benchmark_MMD(n, m):\n",
        "  image_size = round(m**0.5)\n",
        "  pad_size = 0\n",
        "  sample_ds, _, _ = process_mnist(seed=42, ds_size=n, image_size=image_size, pad_size=pad_size)\n",
        "\n",
        "  kernel = MMD_Mnist(image_size=image_size, pad_size=pad_size)\n",
        "  kernel_params = kernel._initialise_params(42)\n",
        "\n",
        "  def run_ker(x, y):\n",
        "    return kernel(x, y, kernel_params)\n",
        "  \n",
        "  run_ker_left = jax.vmap(run_ker, in_axes=(0, None))\n",
        "  run_ker_right = jax.vmap(run_ker_left, in_axes=(None, 0))\n",
        "  jitted_run_ker = jax.jit(run_ker_right)\n",
        "\n",
        "  # jit for speed.\n",
        "  _ = jitted_run_ker(sample_ds, sample_ds).block_until_ready()\n",
        "\n",
        "  tic = time.perf_counter()\n",
        "  jitted_run_ker(sample_ds, sample_ds).block_until_ready()\n",
        "  toc = time.perf_counter()\n",
        "\n",
        "  print(f\"{toc - tic:0.6f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3TYLxSOb3Bn",
        "outputId": "a13c6fc5-62dd-4c56-ed41-f192c3911f47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.001422 seconds\n"
          ]
        }
      ],
      "source": [
        "run_benchmark_MMD(50, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p8FO4jvb3ET",
        "outputId": "1372213e-eda7-404d-f991-1d13a2664629"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.004920 seconds\n"
          ]
        }
      ],
      "source": [
        "run_benchmark_MMD(100, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwccKy5jcXYV",
        "outputId": "fda856db-caeb-47a1-da8d-df4c8b4ec778"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.055241 seconds\n"
          ]
        }
      ],
      "source": [
        "run_benchmark_MMD(100, 400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcSS0v4FcXbi",
        "outputId": "3916b46a-3459-4edb-8d11-87c313707f01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.682734 seconds\n"
          ]
        }
      ],
      "source": [
        "run_benchmark_MMD(400, 400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zqF6vf_cXfh",
        "outputId": "2fb0625d-c304-40ec-df73-3d8d91f1e028"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.681392 seconds\n"
          ]
        }
      ],
      "source": [
        "run_benchmark_MMD(400, 625)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTPeD8u1cXh_",
        "outputId": "2dd5697c-7cc6-4044-847e-ff6572c81f00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10.833395 seconds\n"
          ]
        }
      ],
      "source": [
        "run_benchmark_MMD(1000, 625)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDbYs8nScXkR",
        "outputId": "71d9e6c7-dee7-4981-e7f0-8a4e14bdb4b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14.206577 seconds\n"
          ]
        }
      ],
      "source": [
        "run_benchmark_MMD(1000, 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAdZX6nwUiHL",
        "outputId": "11575008-9385-4bd3-9533-20933fe3f140"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.026048 seconds\n"
          ]
        }
      ],
      "source": [
        "def run_benchmark_Sinkhorn(n, m):\n",
        "  image_size = round(m**0.5)\n",
        "  pad_size = 0\n",
        "  sample_ds, _, _ = process_mnist(seed=42, ds_size=n, image_size=image_size, pad_size=pad_size)\n",
        "\n",
        "  kernel = gpx.kernels.RBF()\n",
        "  kernel_params = kernel._initialise_params(42)\n",
        "  kernel_params = {'lengthscale': jnp.array([0.3], dtype=jnp.float32), 'variance': jnp.array([1.], dtype=jnp.float32)}\n",
        "\n",
        "  cloud_embedding_fn_closure = partial(cloud_embedding_fn, image_size=image_size, pad_size=pad_size)\n",
        "\n",
        "  def run_ker(embed_x, embed_y):\n",
        "    return kernel(embed_x, embed_y, kernel_params)\n",
        "\n",
        "  def bench_ker(x, y):\n",
        "    embed_x, _ = cloud_embedding_fn_closure(cloud=x, mu=mu)\n",
        "    embed_y, _ = cloud_embedding_fn_closure(cloud=y, mu=mu)\n",
        "    run_ker_left = jax.vmap(run_ker, in_axes=(0, None))\n",
        "    run_ker_right = jax.vmap(run_ker_left, in_axes=(None, 0))\n",
        "    return run_ker_right(embed_x, embed_y)\n",
        "\n",
        "  sample_ds = onp.random.uniform(size=sample_ds.shape) + 0.1\n",
        "  sample_ds = sample_ds / onp.sum(sample_ds, axis=-1, keepdims=True)\n",
        "  sample_ds = jnp.array(sample_ds, dtype=jnp.float32)\n",
        "\n",
        "  # jit for speed.\n",
        "  jitted_run_ker = jax.jit(bench_ker)\n",
        "\n",
        "  useless = jitted_run_ker(sample_ds, sample_ds).block_until_ready()\n",
        "\n",
        "  tic = time.perf_counter()\n",
        "  jitted_run_ker(sample_ds, sample_ds).block_until_ready()\n",
        "  toc = time.perf_counter()\n",
        "\n",
        "  print(f\"{toc - tic:0.6f} seconds\")\n",
        "\n",
        "run_benchmark_Sinkhorn(50, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egSSXuLQVmCz",
        "outputId": "d4cbe179-b8a1-4ac8-f478-9a7c6cbb8282"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.026524 seconds\n"
          ]
        }
      ],
      "source": [
        "run_benchmark_Sinkhorn(50, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdvoAdCSVmFl",
        "outputId": "0457f788-517a-43ca-b24f-7f2734f82dee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.033414 seconds\n"
          ]
        }
      ],
      "source": [
        "run_benchmark_Sinkhorn(100, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ymD-0kKVmHQ",
        "outputId": "89450218-3725-4180-ac0b-eec8b1f1ce14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.024946 seconds\n"
          ]
        }
      ],
      "source": [
        "run_benchmark_Sinkhorn(100, 400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yb60Qf_VmKy",
        "outputId": "86942c24-30a1-4f49-94c3-20293acfa51a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.071065 seconds\n"
          ]
        }
      ],
      "source": [
        "run_benchmark_Sinkhorn(400, 400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvrvst68bVhe",
        "outputId": "73be8166-f8ca-415c-b72d-c4b098cc8ab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.097655 seconds\n"
          ]
        }
      ],
      "source": [
        "run_benchmark_Sinkhorn(400, 625)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feRNOz3JbVkN",
        "outputId": "5e8458d4-71fa-42c9-ee6e-d67d06626373"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.115044 seconds\n"
          ]
        }
      ],
      "source": [
        "run_benchmark_Sinkhorn(1000, 625)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5_PElk4bVo-",
        "outputId": "16d15036-dd46-4959-def5-d3c0a7be9729"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.156624 seconds\n"
          ]
        }
      ],
      "source": [
        "run_benchmark_Sinkhorn(1000, 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFlt1CvgMI12"
      },
      "outputs": [],
      "source": [
        "from jaxopt import OptaxSolver\n",
        "import optax\n",
        "\n",
        "\n",
        "def run_experiment(seeds, sample_train, sample_test, y_train, y_test):\n",
        "  ncols = 3\n",
        "  f, ax = plt.subplots(nrows=1, ncols=1)\n",
        "\n",
        "  kernel = MMD_Mnist()  # gpx.RBF()\n",
        "  prior = gpx.Prior(kernel=kernel)\n",
        "  likelihood = gpx.Bernoulli(num_datapoints=len(sample_train))\n",
        "  # likelihood = gpx.Gaussian(num_datapoints=len(sample_train))\n",
        "  posterior = prior * likelihood\n",
        "\n",
        "  parameter_state = gpx.initialise(posterior, key=None)\n",
        "  _, trainable, constrainer, unconstrainer = parameter_state.unpack()\n",
        "\n",
        "  kwargs = dict(\n",
        "      sinkhorn_epsilon               = 1e-1 ,\n",
        "      lse_mode                       = True ,\n",
        "      implicit_differentiation       = False,\n",
        "      implicit_solver_ridge_kernel   = 1e-2 ,  # promote zero sum solutions\n",
        "      implicit_solver_ridge_identity = 1e-2 ,  # regul for ill-posed problem\n",
        "  )\n",
        "\n",
        "  def loss_fn(params):\n",
        "    kernel_params = params['kernel_params']\n",
        "    X_train = sample_train\n",
        "    kernel_params = gpx.parameters.trainable_params(kernel_params, trainable)\n",
        "    D = gpx.Dataset(X=X_train, y=y_train)\n",
        "    nll = posterior.marginal_log_likelihood(D, constrainer, negative=True)\n",
        "    return nll(kernel_params)\n",
        "\n",
        "  opt = LBFGS(fun=loss_fn, maxiter=120, tol=1e-3, maxls=20, has_aux=False)\n",
        "  # optax_opt = optax.adam(learning_rate=5e-2)\n",
        "  # opt = OptaxSolver(opt=optax_opt, fun=loss_fn, maxiter=100, has_aux=True)\n",
        "\n",
        "  @jax.jit\n",
        "  def opt_update(params, opt_state):\n",
        "    return opt.update(params, opt_state)\n",
        "\n",
        "  test_metrics_avg = []\n",
        "  for i, seed in enumerate(seeds):\n",
        "\n",
        "    key = jax.random.PRNGKey(seed)\n",
        "\n",
        "    kernel_params, metrics = learn(opt, opt_update, loss_fn,\n",
        "          posterior, likelihood, constrainer, unconstrainer,\n",
        "          sample_train, sample_test,\n",
        "          y_train, y_test)\n",
        "    \n",
        "    losses, test_metrics, train_metrics = metrics\n",
        "    test_metrics_avg.append(test_metrics)\n",
        "\n",
        "    if i+1 == len(seeds):\n",
        "      ax.axis('equal')\n",
        "      plot_loss(losses, ax)\n",
        "  \n",
        "  return (kernel_params,), metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYbuEDQ0UYE-"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgeS-Rd_UAU8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "seeds = [997]  #, 11, 55, 79, 46, 98, 73, 22, 34, 76]\n",
        "plt.rcParams[\"figure.figsize\"] = (24, 8)\n",
        "train_size = 200\n",
        "test_size = 1000  # less stochastic.\n",
        "ds_size = train_size + test_size\n",
        "ds_seeds = [615, 31, 987, 156, 987, 29, 68, 648, 21, 94, 49, 165, 1, 64561, 471, 32, 986, 7, 38, 968, 14, 65, 78, 9, 33]\n",
        "tests_accs = []\n",
        "for ds_seed in ds_seeds:\n",
        "  sample_ds, target_ds, sample_naked = process_mnist(seed=ds_seed, ds_size=ds_size)\n",
        "  # sample_ds, _ = cloud_embedding_fn(sample_ds, mu)\n",
        "  sample_train, sample_test, y_train, y_test = train_test_split(sample_ds, target_ds, train_size=train_size, shuffle=True, random_state=89)\n",
        "  (kernel_params,), metrics = run_experiment(seeds, sample_train, sample_test, y_train, y_test)\n",
        "  test_metric = metrics[1]\n",
        "  test_acc = test_metric[1]\n",
        "  tests_accs.append(test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuOernr8oOcm"
      },
      "outputs": [],
      "source": [
        "def save_metrics(metrics):\n",
        "  losses, test_metrics, train_metrics = metrics\n",
        "  test_metrics = onp.array([test_metrics])\n",
        "  train_metrics = onp.array([train_metrics])\n",
        "  train_test_metrics = onp.concatenate([train_metrics, test_metrics])\n",
        "  df_metrics = pd.DataFrame(data=train_test_metrics, columns=['evs', 'rmse', 'mae', 'log_likelihood'])\n",
        "  df_metrics['name'] = ['train', 'test']\n",
        "  df_metrics.to_csv('toy_score.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnRBaDa_Vgt2"
      },
      "outputs": [],
      "source": [
        "kwargs = dict(\n",
        "      sinkhorn_epsilon               = 1e-1 ,\n",
        "      lse_mode                       = True ,\n",
        "      implicit_differentiation       = False,\n",
        "      implicit_solver_ridge_kernel   = 1e-2 ,  # promote zero sum solutions\n",
        "      implicit_solver_ridge_identity = 1e-2 ,  # regul for ill-posed problem\n",
        ")\n",
        "kernel = MMD_Mnist()  # gpx.RBF()\n",
        "prior = gpx.Prior(kernel=kernel)\n",
        "likelihood = gpx.Bernoulli(num_datapoints=len(sample_train))\n",
        "# likelihood = gpx.Gaussian(num_datapoints=len(sample_train))\n",
        "posterior = prior * likelihood\n",
        "parameter_state = gpx.initialise(posterior, key=None)\n",
        "_, trainable, constrainer, unconstrainer = parameter_state.unpack()\n",
        "evaluate(kernel_params,\n",
        "         posterior, likelihood, constrainer, unconstrainer,\n",
        "         sample_train, sample_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4YECd6A3EQx"
      },
      "outputs": [],
      "source": [
        "tests_accs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdRi7vouyR5K"
      },
      "outputs": [],
      "source": [
        "onp.mean(sorted(tests_accs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkiIG4ksyK5Y"
      },
      "outputs": [],
      "source": [
        "onp.std(sorted(tests_accs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlayHkCcyS84"
      },
      "outputs": [],
      "source": [
        "plt.imshow(process_mnist(seed=ds_seed, ds_size=ds_size)[0][0].reshape((24,24)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WT7Q1wKPaUHW"
      },
      "outputs": [],
      "source": [
        "mu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgrmO1X7oz2G"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
