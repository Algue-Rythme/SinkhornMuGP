{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the paper\n",
    "\n",
    "We attempt to reproduce and beat the results of \"Sliced Wasserstein Kernels for Probability Distributions\", https://openaccess.thecvf.com/content_cvpr_2016/papers/Kolouri_Sliced_Wasserstein_Kernels_CVPR_2016_paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPukgpJoRVA8"
   },
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from jax.config import config\n",
    "\n",
    "run64 = False\n",
    "if run64:\n",
    "    config.update(\"jax_enable_x64\", True)\n",
    "    global_type = jnp.float64\n",
    "else:\n",
    "    global_type = jnp.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UdOhJnZDRY2B"
   },
   "outputs": [],
   "source": [
    "import ott\n",
    "from ott.geometry import pointcloud\n",
    "from ott.core import sinkhorn\n",
    "from ott.tools import transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdjmzmCIk7lY"
   },
   "outputs": [],
   "source": [
    "def get_indexes_support(n, m):\n",
    "    rows = jnp.expand_dims(jnp.arange(n, dtype=jnp.float32), axis=1)\n",
    "    rows = jnp.tile(rows, m) / n  # renormalize\n",
    "    cols = jnp.expand_dims(jnp.arange(m, dtype=jnp.float32), axis=1)\n",
    "    cols = jnp.tile(cols, n).T / m  # renormalize\n",
    "    coords = jnp.stack([rows, cols], axis=-1)\n",
    "    coords = jnp.reshape(coords, newshape=(n*m, 2))\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Hide any GPUs from TensorFlow. Otherwise TF might reserve memory and make\n",
    "# it unavailable to JAX.\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def retrieve_label(file_path):\n",
    "    suffix = tf.strings.split(file_path, 'T')[-1]\n",
    "    suffix = tf.strings.split(suffix, '.')[0]\n",
    "    suffix = tf.strings.split(suffix, '_')\n",
    "    class_label = tf.strings.to_number(suffix[0], out_type=tf.int64)\n",
    "    image_index = tf.strings.to_number(suffix[1], out_type=tf.int64)\n",
    "    return class_label, image_index\n",
    "\n",
    "def process_filename(file_path):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.io.decode_jpeg(img, channels=1)\n",
    "    img = tf.squeeze(img)\n",
    "    class_label, image_index = retrieve_label(file_path)\n",
    "    return img, class_label, image_index \n",
    "\n",
    "def create_texture_dataset():\n",
    "    ds_images = tf.data.Dataset.list_files(\n",
    "        \"textures/*/*.jpg\", shuffle=True\n",
    "    )\n",
    "    ds_images = ds_images.map(process_filename)\n",
    "    return ds_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def vizualize_features(features, channels='first', **kwargs):\n",
    "    if channels == 'last':\n",
    "        features = jnp.transpose(features, axes=[2, 3, 0, 1])\n",
    "    n, m = features.shape[2], features.shape[3]\n",
    "    n_row, n_col = features.shape[0], features.shape[1]\n",
    "    imgs = [features[i,j] for i, j in itertools.product(range(n_row), range(n_col))]\n",
    "    _, axs = plt.subplots(n_row, n_col, figsize=(n_col*4, n_row*4))\n",
    "    if n_row == 1 and n_col == 1:\n",
    "        axs = [axs]\n",
    "    else:\n",
    "        axs = axs.flatten()\n",
    "    for img, ax in zip(imgs, axs):\n",
    "        ax.imshow(img, **kwargs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_dataset = create_texture_dataset().as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import graycomatrix\n",
    "\n",
    "def fill_glcm(glcm, lbda):\n",
    "    eps  = 0.1 / (glcm.shape[-2]*glcm.shape[-1])\n",
    "    mask = jnp.where(glcm > 0, 0., 1.)\n",
    "    mask = mask / (jnp.sum(mask, axis=[-2,-1], keepdims=True) + eps)\n",
    "    glcm = glcm + lbda * mask\n",
    "    glcm = glcm / jnp.sum(glcm, axis=[-2,-1], keepdims=True)\n",
    "    return glcm\n",
    "\n",
    "def GLCM(img, depth=2, width=4, compression=0, lbda=0.):\n",
    "    img        = onp.floor_divide(img, 1 << compression)\n",
    "    distances  = onp.arange(1, depth+1)\n",
    "    if width == 2:\n",
    "        angles = jnp.array([0, jnp.pi / 2])\n",
    "    else:\n",
    "        angles = onp.linspace(0, 2*jnp.pi, num=width, endpoint=False)\n",
    "    glcm       = graycomatrix(img, distances, angles,\n",
    "                             levels=256 // (1 << compression),\n",
    "                             normed=True, symmetric=False)\n",
    "    glcm       = onp.transpose(glcm, axes=[2, 3, 0, 1])\n",
    "    glcm       = jnp.array(glcm, dtype=global_type)\n",
    "    if lbda > 0.:\n",
    "        # force support with positive mass\n",
    "        glcm = fill_glcm(glcm, lbda)\n",
    "    return glcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def get_images_embedding(geom, glcm_features, mu, **kwargs):\n",
    "    num_gray_levels = glcm_features.shape[-1]\n",
    "    depth           = glcm_features.shape[0]\n",
    "    width           = glcm_features.shape[1]\n",
    "    g_embeddings = []\n",
    "    for depth in range(glcm_features.shape[0]):\n",
    "        for width in range(glcm_features.shape[1]):\n",
    "            glcm = glcm_features[depth, width].ravel()\n",
    "            ot_sol = sinkhorn.sinkhorn(geom, glcm, mu, **kwargs)\n",
    "            g_embeddings.append(ot_sol.g)\n",
    "    g_embedding = jnp.concatenate(g_embeddings, axis=0)\n",
    "    return g_embedding, ot_sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression = 2\n",
    "depth = 2\n",
    "width = 2\n",
    "num_gray_levels = 256 // (1 << compression)\n",
    "lbda = 0.1  # multiplicator of smallest mass available\n",
    "epsilon = 1e-3  # in Sinkhorn regularized\n",
    "n, m = 480, 640\n",
    "mu_type = \"average\"  # or mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def compute_uniform_mu():\n",
    "    uniform = jnp.ones((num_gray_levels*num_gray_levels,), dtype=global_type)\n",
    "    return uniform / jnp.sum(uniform, axis=-1, keepdims=True)\n",
    "\n",
    "def compute_average_mu():\n",
    "    glcms = []\n",
    "    try:\n",
    "        ds = create_texture_dataset()\n",
    "        pbar = tqdm.tqdm(total=int(ds.cardinality()))\n",
    "        for image, label, idx in ds:\n",
    "            img = image.numpy()\n",
    "            glcm = GLCM(img, depth=depth, width=width, compression=compression, lbda=lbda)\n",
    "            glcms.append(glcm)\n",
    "            pbar.update()\n",
    "    finally:\n",
    "        pbar.close()\n",
    "    mu = jnp.mean(jnp.stack(glcms), axis=[0,1,2])  # average over images, depths, widths\n",
    "    mu = fill_glcm(mu, lbda)\n",
    "    mu = mu.ravel()\n",
    "    return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_glcms = []\n",
    "for img_id in range(1, 9+1):\n",
    "    file_path = f\"img{img_id}.jpg\"\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.io.decode_jpeg(img, channels=1)\n",
    "    img = tf.squeeze(img)\n",
    "    img = img.numpy()\n",
    "    glcm = GLCM(img, depth=depth, width=width, compression=compression, lbda=lbda)\n",
    "    glcm = glcm[0,0]\n",
    "    toy_glcms.append(glcm)\n",
    "toy_glcms = onp.array(toy_glcms).reshape((3,3)+glcm.shape)\n",
    "vizualize_features(toy_glcms, vmin=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = next(it_dataset)[0]\n",
    "glcm = GLCM(img, depth=depth, width=width, compression=compression, lbda=lbda)\n",
    "vizualize_features(glcm, vmin=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ott.geometry import grid\n",
    "geom = grid.Grid(grid_size=[num_gray_levels, num_gray_levels], epsilon=epsilon)\n",
    "if mu_type == \"uniform\":\n",
    "    mu = compute_uniform_mu()\n",
    "elif mu_type == \"average\":\n",
    "    mu = compute_average_mu()\n",
    "vizualize_features(mu.reshape((1,1,num_gray_levels,num_gray_levels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glcm = GLCM(img, depth=depth, width=width, compression=compression, lbda=lbda)\n",
    "g_embeddings, ot_sol = get_images_embedding(geom, glcm, mu)\n",
    "img_embedding = g_embeddings.reshape(glcm.shape)\n",
    "print(f\"errors={ot_sol.errors[0],ot_sol.errors[-1]}, converged={ot_sol.converged}, cost={ot_sol.reg_ot_cost:.4f}\")\n",
    "vizualize_features(img_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_describe = pd.DataFrame(img_embedding.ravel())\n",
    "desc = df_describe.describe().transpose()\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm \n",
    "\n",
    "ds = create_texture_dataset()\n",
    "features = []\n",
    "raw = []\n",
    "labels = []\n",
    "indices = []\n",
    "try:\n",
    "    pbar = tqdm.tqdm(total=int(ds.cardinality()))\n",
    "    converged_hist = []\n",
    "    for image, label, idx in ds:\n",
    "        img = image.numpy()\n",
    "        glcm = GLCM(img, depth=depth, width=width, compression=compression, lbda=lbda)\n",
    "        raw.append(glcm.ravel())\n",
    "        g_embeddings, ot_sol = get_images_embedding(geom, jnp.array(glcm), jnp.array(mu))\n",
    "        features.append(g_embeddings.reshape(glcm.shape))\n",
    "        labels.append(label)\n",
    "        indices.append(idx)\n",
    "        converged_hist.append(ot_sol.converged)\n",
    "        pbar.set_description(f\"converged={jnp.mean(jnp.array(converged_hist))*100:.2f}%\")\n",
    "        pbar.update()\n",
    "    features = jnp.stack(features).reshape((len(features), -1))\n",
    "    raw = jnp.stack(raw, axis=0).reshape((len(raw), -1))\n",
    "    labels = jnp.stack([label.numpy() for label in labels])\n",
    "    indices = jnp.stack([idx.numpy() for idx in indices])\n",
    "finally:\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'SinkhornKernelLargeScale.ipynb'\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "import math\n",
    "config = SimpleNamespace(\n",
    "    depth=depth,\n",
    "    width=width,\n",
    "    compression=compression,\n",
    "    num_gray_levels=num_gray_levels,\n",
    "    mu_type=mu_type,\n",
    "    lbda=lbda\n",
    ")\n",
    "wandb.init(project=\"sinkhorn_kernel\", config=config.__dict__)\n",
    "table = wandb.Table(columns=['Type', 'Best acc', 'Best params'])\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "grid_cv_features = GridSearchCV(svc, param_grid={'gamma':['scale','auto'], 'C':[0.1, 1, 10, 100, 1000]},\n",
    "                                cv=5, scoring='accuracy',  # balanced learning so ok.\n",
    "                                n_jobs=12)  # keep 4 cores for other process running in parallel\n",
    "grid_cv_features = grid_cv_features.fit(features, labels)\n",
    "grid_cv_features.best_score_, grid_cv_features.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(**grid_cv_features.best_params_)\n",
    "svc.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.add_data('features', grid_cv_features.best_score_, grid_cv_features.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "grid_cv_raw = GridSearchCV(svc, param_grid={'gamma':['scale','auto'], 'C':[0.1, 1, 10, 100, 1000]},\n",
    "                           cv=5, scoring='accuracy',  # balanced learning so ok.\n",
    "                           n_jobs=12)  # keep 4 cores for other process running in parallel\n",
    "grid_cv_raw = grid_cv_raw.fit(raw.astype(jnp.float64), labels)\n",
    "grid_cv_raw.best_score_, grid_cv_raw.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.add_data('raw', grid_cv_features.best_score_, grid_cv_features.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "grid_cv_features = GridSearchCV(svc, param_grid={'gamma':['scale','auto'], 'C':[1, 10, 50, 100, 200]},\n",
    "                                cv=5, scoring='accuracy',  # balanced learning so ok.\n",
    "                                n_jobs=12)  # keep 4 cores for other process running in parallel\n",
    "grid_cv_features = grid_cv_features.fit(onp.array(features, dtype=onp.float64), labels)\n",
    "grid_cv_features.best_score_, grid_cv_features.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "grid_cv_raw = GridSearchCV(svc, param_grid={'gamma':['scale','auto'], 'C':[1, 10, 50, 100, 200]},\n",
    "                           cv=5, scoring='accuracy',  # balanced learning so ok.\n",
    "                           n_jobs=12)  # keep 4 cores for other process running in parallel\n",
    "grid_cv_raw = grid_cv_raw.fit(onp.array(raw, dtype=onp.float64), labels)\n",
    "grid_cv_raw.best_score_, grid_cv_raw.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SinkhornKernel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
